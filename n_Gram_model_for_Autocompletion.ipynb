{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2TXPpbvcLVm",
        "outputId": "b0612043-64b6-44c9-b33d-fd50b1ce451b"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv==1.0.1 expects==0.9.0 datasets==2.19.0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nrWhh_FugN9I"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b9HhTY0sbwg4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "from expects import contain_exactly, equal, expect\n",
        "\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "ccb038298cc54251ab9cb7cc802c3c65",
            "4aeb773899024f04858793b194b075b5",
            "cfa76cf30fad4426b711533905a6bdde",
            "947c503af7fb40e98d71cbea5041a8b8",
            "04cd26984f914b7a8874049254fd0258",
            "c9b7a630e07e4a3893b4402d5d37ab72",
            "f175789a77204e528b9ffcf4974f7fe9",
            "32dca3f9ee694f65b70100f0dc5427fc",
            "8bcc75607e0e4948a2d2f16e2c04548a",
            "7240bda92d5843df997bcaee596da264",
            "27d9078f648b410e8a8526aad4714dbd",
            "f0092bfa570649b29f7d868eb6ce21b2",
            "acea3c84d96c423d86494e7b3c0be4b7",
            "7964bb38775e400cb5bc880ca2572eae",
            "e976d14a24a1473e9d7dc40e9ca0a6ef",
            "2ef399f7b8654954ab4e6583eb6a7eea",
            "6262e507f1bf499b81eb0cbca23cd22d",
            "1c842c87e2044dcca0a14a63a0ff4670",
            "d5c4e06bdc29463bbe999660f40a801f",
            "a509a06d08e7497ca6629604c8e1a173",
            "c6959e78946d4dc2bcb241820f4a6ce2",
            "8a564412f2c345d68b703f5986e0ed83",
            "84b7ff0eb2d34a7fa7091e66a09a7f44",
            "83f16dc964a948cea62d076f883e99c6",
            "fb433e5b56cd42a5813861310f2693ce",
            "252d3ef4498f4028b50055c06f9cfb7f",
            "b7d3810df42046eabbf6b024d49060b9",
            "b94920db784f4bfc9112ee94ebf41149",
            "6f09d0464bf84a21b921467e068afa6b",
            "d7cf1524a9bd4dad8ee8bf7fc9d773bf",
            "574339849abc480b85aa734f758a56fe",
            "6bd1d041a9f04d36ae6fd00dbda17a01",
            "dabee55ea6d34f2da1e72d37ce8140ac"
          ]
        },
        "id": "3dyiLv6beTQW",
        "outputId": "0ab5f331-1ccf-4f62-a30e-d329be37920c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vaibhavsethia07/.local/share/virtualenvs/n-gram-autocomplete-H4unCibe/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output', 'text'],\n",
              "    num_rows: 52002\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"vicgalle/alpaca-gpt4\")\n",
        "\n",
        "dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "JYy2RbjSrAzF",
        "outputId": "e4e150e4-d571-4f0e-e2df-761407215353"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Give three tips for staying healthy.</td>\n",
              "      <td></td>\n",
              "      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the three primary colors?</td>\n",
              "      <td></td>\n",
              "      <td>The three primary colors are red, blue, and ye...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Describe the structure of an atom.</td>\n",
              "      <td></td>\n",
              "      <td>An atom is the basic building block of all mat...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can we reduce air pollution?</td>\n",
              "      <td></td>\n",
              "      <td>There are several ways to reduce air pollution...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Describe a time when you had to make a difficu...</td>\n",
              "      <td></td>\n",
              "      <td>As an AI assistant, I do not have my own perso...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         instruction input  \\\n",
              "0               Give three tips for staying healthy.         \n",
              "1                 What are the three primary colors?         \n",
              "2                 Describe the structure of an atom.         \n",
              "3                   How can we reduce air pollution?         \n",
              "4  Describe a time when you had to make a difficu...         \n",
              "\n",
              "                                              output  \\\n",
              "0  1. Eat a balanced and nutritious diet: Make su...   \n",
              "1  The three primary colors are red, blue, and ye...   \n",
              "2  An atom is the basic building block of all mat...   \n",
              "3  There are several ways to reduce air pollution...   \n",
              "4  As an AI assistant, I do not have my own perso...   \n",
              "\n",
              "                                                text  \n",
              "0  Below is an instruction that describes a task....  \n",
              "1  Below is an instruction that describes a task....  \n",
              "2  Below is an instruction that describes a task....  \n",
              "3  Below is an instruction that describes a task....  \n",
              "4  Below is an instruction that describes a task....  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51997</th>\n",
              "      <td>Generate an example of what a resume should li...</td>\n",
              "      <td></td>\n",
              "      <td>**John Doe**\\n\\n**Contact Information:**\\n\\n12...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51998</th>\n",
              "      <td>Arrange the items given below in the order to ...</td>\n",
              "      <td>cake, me, eating</td>\n",
              "      <td>Me eating cake.</td>\n",
              "      <td>Below is an instruction that describes a task,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51999</th>\n",
              "      <td>Write an introductory paragraph about a famous...</td>\n",
              "      <td>Michelle Obama</td>\n",
              "      <td>Michelle Obama, born January 17, 1964, in Chic...</td>\n",
              "      <td>Below is an instruction that describes a task,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52000</th>\n",
              "      <td>Generate a list of five things one should keep...</td>\n",
              "      <td></td>\n",
              "      <td>1. Evaluate your reasons: It's important to ta...</td>\n",
              "      <td>Below is an instruction that describes a task....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52001</th>\n",
              "      <td>Analyze the given legal document and explain t...</td>\n",
              "      <td>The following is an excerpt from a contract be...</td>\n",
              "      <td>The contract between Company A and Company B o...</td>\n",
              "      <td>Below is an instruction that describes a task,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             instruction  \\\n",
              "51997  Generate an example of what a resume should li...   \n",
              "51998  Arrange the items given below in the order to ...   \n",
              "51999  Write an introductory paragraph about a famous...   \n",
              "52000  Generate a list of five things one should keep...   \n",
              "52001  Analyze the given legal document and explain t...   \n",
              "\n",
              "                                                   input  \\\n",
              "51997                                                      \n",
              "51998                                   cake, me, eating   \n",
              "51999                                     Michelle Obama   \n",
              "52000                                                      \n",
              "52001  The following is an excerpt from a contract be...   \n",
              "\n",
              "                                                  output  \\\n",
              "51997  **John Doe**\\n\\n**Contact Information:**\\n\\n12...   \n",
              "51998                                    Me eating cake.   \n",
              "51999  Michelle Obama, born January 17, 1964, in Chic...   \n",
              "52000  1. Evaluate your reasons: It's important to ta...   \n",
              "52001  The contract between Company A and Company B o...   \n",
              "\n",
              "                                                    text  \n",
              "51997  Below is an instruction that describes a task....  \n",
              "51998  Below is an instruction that describes a task,...  \n",
              "51999  Below is an instruction that describes a task,...  \n",
              "52000  Below is an instruction that describes a task....  \n",
              "52001  Below is an instruction that describes a task,...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(dataset[\"train\"])\n",
        "\n",
        "df.head()\n",
        "\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksxd4dIdv9Vu"
      },
      "source": [
        "# Pre-processing 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-m2OtkFfrHc",
        "outputId": "22fbabbb-9b18-4b0a-f2c7-633a1ef90234"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Give three tips for staying healthy. 1. Eat a ...\n",
              "1    What are the three primary colors? The three p...\n",
              "2    Describe the structure of an atom. An atom is ...\n",
              "3    How can we reduce air pollution? There are sev...\n",
              "4    Describe a time when you had to make a difficu...\n",
              "Name: instruction_output, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"instruction_output\"] = df[[\"instruction\", \"output\"]].apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "df[\"instruction_output\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "SquukrFBjzNR",
        "outputId": "ef11171d-2178-4a27-eee9-965eeaf163a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What are the three primary colors? The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"instruction_output\"].loc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uQ35l4pk49-",
        "outputId": "caa82c1e-1b0b-4893-e9ba-fbad04826bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/vaibhavsethia07/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install --user -U nltk==3.8.1\n",
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn9Ejku5v2bw"
      },
      "source": [
        "## Split to sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "raFuFMNpipIx"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "\n",
        "def tokenize_text_to_sentences(data: pd.Series):\n",
        "  \"\"\"\n",
        "  Split data by line break \"\\n\", sentence completion tokens into sentences\n",
        "  Args:\n",
        "    data: pandas.Series\n",
        "  Returns:\n",
        "    sentences: List[str]\n",
        "  \"\"\"\n",
        "  pst = PunktSentenceTokenizer()\n",
        "  sentences = list()\n",
        "  for text in data.values:\n",
        "\n",
        "    # Tokenize text into sentences\n",
        "    text_sentences = pst.tokenize(text=text)\n",
        "    sentences.extend(text_sentences)\n",
        "\n",
        "  return sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85V81eBp4gw-"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bKCQKOYmmwEz"
      },
      "outputs": [],
      "source": [
        "test_data = pd.DataFrame({\"test\": [\"This is a random text.  This is another random text! 1. Again, you know. Nah I',m just kidding!!\",\n",
        "        \"Sky is blue. Leaves are green. Roses are red.\"]})\n",
        "\n",
        "expected = [\"This is a random text.\",\n",
        "            \"This is another random text!\",\n",
        "            \"1.\",\n",
        "            \"Again, you know.\",\n",
        "            \"Nah I',m just kidding!\",\n",
        "            \"!\",\n",
        "            \"Sky is blue.\",\n",
        "            \"Leaves are green.\",\n",
        "            \"Roses are red.\"]\n",
        "\n",
        "\n",
        "actual = tokenize_text_to_sentences(test_data[\"test\"])\n",
        "expect(actual).to(contain_exactly(*expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdjQsAkxwAmU"
      },
      "source": [
        "## Tokenize Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eRVuS8N_szhL"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from typing import List\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def clean_words(words: List[str]):\n",
        "  \"\"\"\n",
        "  Clean the words by removing punctuations, and numeric tokens\n",
        "  Args:\n",
        "    words List[str]: Raw words\n",
        "  Returns:\n",
        "    cleaned_words List[str] Words without punctuations, and numeric tokens\n",
        "  \"\"\"\n",
        "\n",
        "  cleaned_words = list()\n",
        "  for word in words:\n",
        "    # Skip punctuations\n",
        "    if word in string.punctuation:\n",
        "      continue\n",
        "\n",
        "    # Skip numbers\n",
        "    if word.isnumeric():\n",
        "      continue\n",
        "\n",
        "    cleaned_words.append(word.lower())\n",
        "  return cleaned_words\n",
        "\n",
        "\n",
        "def tokenize_sentences(sentences: List[str]):\n",
        "  \"\"\"\n",
        "  Tokenize sentences into tokens (words)\n",
        "  Args:\n",
        "    sentences List[str]: List of sentences\n",
        "  Returns:\n",
        "    tokenized_sentences List[List[str]]: List of tokenized sentences\n",
        "  \"\"\"\n",
        "  tokenized_sentences = list()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    # Tokenize sentence into words\n",
        "    words = word_tokenize(text=sentence)\n",
        "    cleaned_words = clean_words(words=words)\n",
        "    if len(cleaned_words) == 0:\n",
        "      continue\n",
        "    tokenized_sentences.append(cleaned_words)\n",
        "\n",
        "  return tokenized_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze6cOYQ44ljU"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vH68vI1T0S96"
      },
      "outputs": [],
      "source": [
        "test_data = [\"This is a random text.\",\n",
        "        \"This is another random text!\",\n",
        "        \"1.\",\n",
        "        \"Again, you know.\",\n",
        "        \"Nah I',m just kidding!\",\n",
        "        \"!\",\n",
        "        \"Sky is blue.\",\n",
        "        \"Leaves are green.\",\n",
        "        \"Roses are red.\"]\n",
        "\n",
        "expecteds = [[\"this\", \"is\", \"a\", \"random\", \"text\"],\n",
        "            [\"this\", \"is\", \"another\", \"random\", \"text\"],\n",
        "            [\"again\", \"you\", \"know\"],\n",
        "            [\"nah\", \"i\", \"m\", \"just\", \"kidding\"],\n",
        "            [\"sky\", \"is\", \"blue\"],\n",
        "            [\"leaves\", \"are\", \"green\"],\n",
        "            [\"roses\", \"are\", \"red\"]\n",
        "            ]\n",
        "\n",
        "actuals = tokenize_sentences(test_data)\n",
        "for actual, expected in zip(actuals, expecteds):\n",
        "  expect(actual).to(contain_exactly(*expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAWNBm4Q2RsI"
      },
      "source": [
        "## Combine Sentence and Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ah7SSDWs2ct8"
      },
      "outputs": [],
      "source": [
        "def get_tokenized_data(data: pd.Series):\n",
        "  \"\"\"\n",
        "  Make a list of tokenized sentences\n",
        "  Args:\n",
        "    data pandas.Series: Raw text\n",
        "  Returns:\n",
        "    tokens List[List[str]]: List of tokenized sentences\n",
        "  \"\"\"\n",
        "  sentences = tokenize_text_to_sentences(data=data)\n",
        "  tokens = tokenize_sentences(sentences=sentences)\n",
        "\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU_TpBdd4m9x"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yKgvQgTq4P7z"
      },
      "outputs": [],
      "source": [
        "test_data = pd.DataFrame({\"test\": [\"This is a random text.  This is another random text! 1. Again, you know. Nah I',m just kidding!!\",\n",
        "        \"Sky is blue. Leaves are green. Roses are red.\"]})\n",
        "\n",
        "expecteds = [[\"this\", \"is\", \"a\", \"random\", \"text\"],\n",
        "            [\"this\", \"is\", \"another\", \"random\", \"text\"],\n",
        "            [\"again\", \"you\", \"know\"],\n",
        "            [\"nah\", \"i\", \"m\", \"just\", \"kidding\"],\n",
        "            [\"sky\", \"is\", \"blue\"],\n",
        "            [\"leaves\", \"are\", \"green\"],\n",
        "            [\"roses\", \"are\", \"red\"]\n",
        "            ]\n",
        "\n",
        "actuals = get_tokenized_data(test_data[\"test\"])\n",
        "for actual, expected in zip(actuals, expecteds):\n",
        "  expect(actual).to(contain_exactly(*expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I28okpFzFn3G"
      },
      "source": [
        "## Split Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaLG-CmBFkva",
        "outputId": "b3e84dee-89ec-4423-b6be-059122d1a603"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "tokenized_data = get_tokenized_data(df[\"instruction_output\"])\n",
        "random.seed(7)\n",
        "random.shuffle(tokenized_data)\n",
        "\n",
        "train_frac = 0.8 # @param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "train_size = int(len(tokenized_data)*train_frac)\n",
        "train_data = tokenized_data[:train_size]\n",
        "test_data = tokenized_data[train_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms3yJTbHH7Vj"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvFB2bdSH9Wu",
        "outputId": "4412bc29-f47c-40c0-d9b9-8050f4a100eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "347,576 are split into 278,060 training entries and 69,516 test set entries.\n"
          ]
        }
      ],
      "source": [
        "actual_data, expected_data = len(tokenized_data), 347576\n",
        "actual_training, expected_training = len(train_data), 278060\n",
        "actual_testing, expected_testing = len(test_data), 69516\n",
        "\n",
        "print(f\"{actual_data:,} are split into {actual_training:,} training entries\"\n",
        "      f\" and {actual_testing:,} test set entries.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuadIWICclji"
      },
      "source": [
        "# Pre-processing 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfTKJWG_cuhU"
      },
      "source": [
        "## Count words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WEPYnPyAckuK"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from collections import defaultdict\n",
        "\n",
        "def create_vocabulary(tokenized_sentences: List[List[str]]):\n",
        "  \"\"\"\n",
        "  Count the number of word appearances in tokenized sentences\n",
        "  Args:\n",
        "    tokenized_sentences List[List[str]]: List of word tokenized sentences\n",
        "  Returns:\n",
        "    vocabulary Dict[str, int]: Dictionary that maps word(str) to its frequency(int)\n",
        "  \"\"\"\n",
        "\n",
        "  vocabulary = defaultdict(int)\n",
        "  for sentence in tokenized_sentences:\n",
        "    for word in sentence:\n",
        "      vocabulary[word]+=1\n",
        "\n",
        "  return dict(vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l00SCXpPf9xh"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kwTkfgndfxXw"
      },
      "outputs": [],
      "source": [
        "from expects import have_keys\n",
        "\n",
        "tokenized_sentences = [['sky', 'is', 'blue'],\n",
        "                       ['leaves', 'are', 'green'],\n",
        "                       ['roses', 'are', 'red']]\n",
        "\n",
        "expected = {\n",
        "    \"sky\":1,\n",
        "    \"is\": 1,\n",
        "    \"blue\": 1,\n",
        "    \"leaves\": 1,\n",
        "    \"are\": 2,\n",
        "    \"green\": 1,\n",
        "    \"roses\": 1,\n",
        "    \"red\": 1\n",
        "}\n",
        "\n",
        "actual = create_vocabulary(tokenized_sentences)\n",
        "\n",
        "expect(actual).to(have_keys(**expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq78IA5Vl4pL"
      },
      "source": [
        "## Out-of-Vocabulary Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3oDyB8megz60"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, FrozenSet\n",
        "\n",
        "def create_closed_vocabulary(vocabulary: Dict[str, int], threshold:int) -> FrozenSet[str]:\n",
        "  \"\"\"\n",
        "  Find the words that appear more than the threshold frequency\n",
        "  Args:\n",
        "    vocabulary Dict[str, int]: Dictionary of word(str), frequency(int) in corpus\n",
        "    threshold int: Minimum number of occurences for a word to be in closed vocabulary\n",
        "  Returns:\n",
        "    closed_vocabulary set: Set of words that appear `threshold` or more times\n",
        "  \"\"\"\n",
        "  closed_vocabulary = set()\n",
        "  for word, freq in vocabulary.items():\n",
        "    if freq >= threshold:\n",
        "      closed_vocabulary.add(word)\n",
        "  return closed_vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA94nHDJop4k"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HPTAgc_SotcQ"
      },
      "outputs": [],
      "source": [
        "vocabulary = {\n",
        "    \"sky\":1,\n",
        "    \"is\": 1,\n",
        "    \"blue\": 1,\n",
        "    \"leaves\": 1,\n",
        "    \"are\": 2,\n",
        "    \"green\": 1,\n",
        "    \"roses\": 1,\n",
        "    \"red\": 1\n",
        "}\n",
        "\n",
        "expected = frozenset([\"are\"])\n",
        "actual = create_closed_vocabulary(vocabulary, threshold=2)\n",
        "\n",
        "expect(actual).to(contain_exactly(*expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC_ml57lpexJ"
      },
      "source": [
        "## Parts Unknown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Xr-3212Xpg0Y"
      },
      "outputs": [],
      "source": [
        "def replace_oov_words_by_unk(tokenized_sentences:List[List[str]], closed_vocabulary:FrozenSet[str], unknown_token=\"<unk>\"):\n",
        "  \"\"\"\n",
        "  Replace words not in the given vocabulary with '<unk>' token.\n",
        "  Args:\n",
        "    tokenized_sentences List[List[str]]: List of word tokenized sentences\n",
        "    vocabulary Set[str]: Set of words that are most frequent\n",
        "    unknown_token str: A string representing unknown (out-of-vocabulary) words\n",
        "  Returns:\n",
        "    replaced_tokenized_sentences List[List[str]]:  List of word tokenized sentences with out-of-vocabulary words converted to `unknown_token`\n",
        "  \"\"\"\n",
        "  replaced_tokenized_sentences = list()\n",
        "\n",
        "  for sentence in tokenized_sentences:\n",
        "    replaced_sentence = list()\n",
        "    for word in sentence:\n",
        "      if word not in closed_vocabulary:\n",
        "        replaced_sentence.append(unknown_token)\n",
        "      else:\n",
        "        replaced_sentence.append(word)\n",
        "\n",
        "    replaced_tokenized_sentences.append(replaced_sentence)\n",
        "\n",
        "  return replaced_tokenized_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV05r-UU0maZ"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe45mUjT0oE7",
        "outputId": "c6ce5872-e32b-4684-9f4e-5909f1e3e1ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentences:\n",
            "[['dogs', 'run'], ['cats', 'and', 'dogs', 'run']]\n",
            "Tokenized sentences with out-of-vocabulary words converted to '<unk>'\n",
            "[['dogs', 'run'], ['<unk>', '<unk>', 'dogs', 'run']]\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentences = [[\"dogs\", \"run\"], [\"cats\", \"and\", \"dogs\", \"run\"]]\n",
        "closed_vocabulary = [\"dogs\", \"run\"]\n",
        "\n",
        "expecteds = [[\"dogs\", \"run\"], [\"<unk>\", \"<unk>\", \"dogs\", \"run\"]]\n",
        "\n",
        "actuals = replace_oov_words_by_unk(tokenized_sentences, closed_vocabulary)\n",
        "\n",
        "print(\"Original sentences:\")\n",
        "print(tokenized_sentences)\n",
        "\n",
        "for actual, expected in zip(actuals, expecteds):\n",
        "  expect(actual).to(contain_exactly(*expected))\n",
        "\n",
        "print(\"Tokenized sentences with out-of-vocabulary words converted to '<unk>'\")\n",
        "print(actuals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1or6nhru5sB"
      },
      "source": [
        "## Combine Closed Vocabulary and Replace Out-Of-Vocabulary words\n",
        "\n",
        "Note that words and tokens are used interchangably."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4B0VhvYDvT8-"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_data:List[List[str]], test_data:List[List[str]], threshold: int):\n",
        "  \"\"\"\n",
        "  Preproces data i.e.\n",
        "    - Create a vocabulary of training data\n",
        "    - Create a closed vocabulary by of tokens that appear at least `threshold` times in the training data.\n",
        "    - Replace the tokens that appear less than `threshold` times by \"<unk>\" for training and test data.\n",
        "    Args:\n",
        "      train_data List[List[str]]: List of word-tokenized sentences for training\n",
        "      test_data List[List[str]]: List of word-tokenized sentences for testing\n",
        "      threshold int:  Minimum number of occurences for a word to be in closed vocabulary\n",
        "    Returns:\n",
        "      (replaced_train_data, replaced_test_data, vocabulary) Tuple[List[List[str]], List[List[str]], Dict[str, int]]: Tuple of\n",
        "      - training data with out-of-vocabulary words replaced by unknown token (<unk>)\n",
        "      - testing data with out-of-vocabulary words replaced by unknown token (<unk>)\n",
        "      - vocabulary\n",
        "  \"\"\"\n",
        "  vocabulary = create_vocabulary(train_data)\n",
        "  closed_vocabulary = create_closed_vocabulary(vocabulary, threshold)\n",
        "\n",
        "  replaced_train_data = replace_oov_words_by_unk(train_data, closed_vocabulary)\n",
        "  replaced_test_data = replace_oov_words_by_unk(test_data, closed_vocabulary)\n",
        "\n",
        "  return replaced_train_data, replaced_test_data, vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0MlShMx1F8s"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL8_LpjL1HzC",
        "outputId": "5f41e5af-f90c-4f3a-f5bd-b9ae0e02a8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repl_tmp_train_data\n",
            "[['dogs', 'run'], ['<unk>', '<unk>', 'dogs', 'run']]\n",
            "repl_tmp_test_data\n",
            "[['dogs', 'run', '<unk>', '<unk>', '<unk>', '<unk>', 'dogs']]\n",
            "tmp_vocabulary\n",
            "{'dogs': 2, 'run': 2, 'cats': 1, 'and': 1}\n"
          ]
        }
      ],
      "source": [
        "tmp_train = [[\"dogs\", \"run\"], [\"cats\", \"and\", \"dogs\", \"run\"]]\n",
        "tmp_test = [[\"dogs\", \"run\", \"after\", \"men\", \"cats\", \"and\", \"dogs\"]]\n",
        "\n",
        "repl_tmp_train_data, repl_tmp_test_data, tmp_vocabulary = preprocess_data(tmp_train, tmp_test, threshold=2)\n",
        "\n",
        "print(\"repl_tmp_train_data\")\n",
        "print(repl_tmp_train_data)\n",
        "expecteds = [[\"dogs\", \"run\"], [\"<unk>\", \"<unk>\", \"dogs\", \"run\"]]\n",
        "for actual, expected in zip(repl_tmp_train_data, expecteds):\n",
        "  expect(actual).to(contain_exactly(*expected))\n",
        "\n",
        "print(\"repl_tmp_test_data\")\n",
        "print(repl_tmp_test_data)\n",
        "expecteds = [[\"dogs\", \"run\", \"<unk>\", \"<unk>\", \"<unk>\", \"<unk>\", \"dogs\"]]\n",
        "for actual, expected in zip(repl_tmp_test_data, expecteds):\n",
        "  expect(actual).to(contain_exactly(*expected))\n",
        "\n",
        "expected = {\n",
        "    \"dogs\": 2,\n",
        "    \"run\": 2,\n",
        "    \"cats\": 1,\n",
        "    \"and\": 1\n",
        "}\n",
        "\n",
        "print(\"tmp_vocabulary\")\n",
        "print(tmp_vocabulary)\n",
        "expect(tmp_vocabulary).to(have_keys(**expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhN2K_wrPv3"
      },
      "source": [
        "# Develop an N-Gram Based Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Cel4c7f2rWEA"
      },
      "outputs": [],
      "source": [
        "%pip install tabulate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZT9-TdFrrrmM"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from tabulate import tabulate\n",
        "\n",
        "TABLE = partial(tabulate, tablefmt=\"orgtbl\", headers=\"keys\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdWfmkSCsvxv"
      },
      "source": [
        "## Count N-Grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_fg3rg4asqlI"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List, DefaultDict\n",
        "from collections import  defaultdict\n",
        "\n",
        "def compute_ngram_dictionary(sentences: List[List[str]], n:int, start_token: str=\"<s>\", end_token:str=\"<e>\") ->DefaultDict[Tuple[str], int]:\n",
        "    \"\"\"\n",
        "    Create a dictionary of `n`-grams of `sentences`\n",
        "        Args:\n",
        "            sentences List[List[str]]: List of word-tokenized sentences\n",
        "            n int: Number of words in sequence\n",
        "            start_token str: Indicate the beginning of the sentence\n",
        "            end_token str: Indicate the ending of the sentence\n",
        "        Returns:\n",
        "            n_gram_counts Dict[Tuple[str], int]: A dictionary that maps a tuple of `n`-words to its frequency\n",
        "    \"\"\"\n",
        "\n",
        "    n_gram_counts = defaultdict(int)\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        # Prepend start token n times, and append end token one time\n",
        "        sentence = [start_token]*n + sentence + [end_token]\n",
        "        print(f\"sentence = {sentence}\")\n",
        "\n",
        "        # Convert list to tuple to use sequence of words as a key in the dictionary\n",
        "        sentence = tuple(sentence)\n",
        "        print(f\"tuple sentence = {sentence}\")\n",
        "        \n",
        "        sentence_length = len(sentence)\n",
        "        for i in range(0, sentence_length-n+1):\n",
        "            n_gram = sentence[i:i+n]\n",
        "            n_gram_counts[n_gram]+=1\n",
        "\n",
        "    return n_gram_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uni-gram\n",
            "sentence = ['<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "defaultdict(<class 'int'>, {('<s>',): 2, ('i',): 1, ('like',): 2, ('a',): 2, ('cat',): 2, ('<e>',): 2, ('this',): 1, ('dog',): 1, ('is',): 1})\n",
            "Bi-gram\n",
            "sentence = ['<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "defaultdict(<class 'int'>, {('<s>', '<s>'): 2, ('<s>', 'i'): 1, ('i', 'like'): 1, ('like', 'a'): 2, ('a', 'cat'): 2, ('cat', '<e>'): 2, ('<s>', 'this'): 1, ('this', 'dog'): 1, ('dog', 'is'): 1, ('is', 'like'): 1})\n"
          ]
        }
      ],
      "source": [
        "from expects import expect, have_keys\n",
        "\n",
        "sentences = [[\"i\",\"like\", \"a\", \"cat\"],\n",
        "             [\"this\", \"dog\", \"is\", \"like\", \"a\", \"cat\"]]\n",
        "\n",
        "print(\"Uni-gram\")\n",
        "expected = {\n",
        "    (\"<s>\",):2,\n",
        "    (\"i\",): 1,\n",
        "    (\"like\",): 2,\n",
        "    (\"a\",): 2,\n",
        "    (\"cat\",): 2,\n",
        "    (\"this\",): 1,\n",
        "    (\"dog\",): 1,\n",
        "    (\"is\",): 1, \n",
        "}\n",
        "\n",
        "actual = compute_ngram_dictionary(sentences, 1)\n",
        "print(actual)\n",
        "expect(actual).to(have_keys(expected))\n",
        "\n",
        "print(\"Bi-gram\")\n",
        "expected = {\n",
        "    (\"<s>\", \"<s>\"): 2,\n",
        "    (\"<s>\", \"i\"): 1,\n",
        "    (\"i\", \"like\"): 1,\n",
        "    (\"like\", \"a\"): 2,\n",
        "    (\"a\", \"cat\"): 2,\n",
        "    (\"<s>\", \"this\"): 1,\n",
        "    (\"this\", \"dog\"): 1,\n",
        "    (\"dog\", \"is\"): 1,\n",
        "    (\"is\", \"like\"): 1,\n",
        "}\n",
        "\n",
        "actual = compute_ngram_dictionary(sentences, 2)\n",
        "print(actual)\n",
        "expect(actual).to(have_keys(expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probability Estimates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import DefaultDict\n",
        "\n",
        "def estimate_probability(word: str,\n",
        "                        previous_n_gram: List[str],\n",
        "                        n_gram_counts: DefaultDict[Tuple[str], int],\n",
        "                        n_plus1_gram_counts: DefaultDict[Tuple[str], int],\n",
        "                        vocabulary_size: int,\n",
        "                        k: float=1.0) -> float:\n",
        "    \"\"\"\n",
        "    Estimate the probabilities of a next word using the n-gram counts with k-smoothing\n",
        "        Args:\n",
        "            word str: Next word\n",
        "            previous_n_gram Tuple[str]: A sequence of words of length n\n",
        "            n_gram_counts Dict[Tuple[str], int]: A dictionary that maps a tuple of `n`-words to its frequency\n",
        "            n_plus1_gram_counts Dict[Tuple[str], int]: Dictionary of counts of (n+1)-grams\n",
        "            vocabulary_size int: Number of words in the vocabulary\n",
        "            k float: Smoothing parameter. Positive constant\n",
        "        Returns:\n",
        "            probability float: Probability of next word using the n-gram counts with k-smoothing\n",
        "    \"\"\"\n",
        "    previous_n_gram = tuple(previous_n_gram)\n",
        "    print(f\"previous_n_gram = {previous_n_gram}\")\n",
        "\n",
        "    # Get the count of the previous n-gram  if exists in the dictionary of n-gram counts else set the count to zero\n",
        "    previous_n_gram_count = n_gram_counts.get(previous_n_gram, 0)\n",
        "\n",
        "    # Calculate the denominator using the count of the previous n gram and apply k-smoothing\n",
        "    denominator = previous_n_gram_count + k*vocabulary_size\n",
        "\n",
        "    # Define n plus 1 gram as the previous n-gram plus the current word\n",
        "    n_plus1_gram = previous_n_gram + (word,)\n",
        "    print(f\"n_plus1_gram = {n_plus1_gram}\")\n",
        "\n",
        "    n_plus1_gram_count = n_plus1_gram_counts.get(n_plus1_gram, 0)\n",
        "\n",
        "    # Calculate the numerator using the count of the n-gram plus current word\n",
        "    numerator = n_plus1_gram_count + k\n",
        "\n",
        "    probabiltiy = numerator/denominator\n",
        "\n",
        "    return probabiltiy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence = ['<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'cat')\n",
            "The estimated probability of word 'cat' given the previous n-gram 'a' is: 0.3333\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from expects import expect, be_true\n",
        "\n",
        "sentences = [[\"i\",\"like\", \"a\", \"cat\"],\n",
        "             [\"this\", \"dog\", \"is\", \"like\", \"a\", \"cat\"]]\n",
        "\n",
        "vocabulary = frozenset(sentences[0]).union(frozenset(sentences[1]))\n",
        "\n",
        "unigram_dictionary = compute_ngram_dictionary(sentences, 1)\n",
        "\n",
        "bigram_dictionary = compute_ngram_dictionary(sentences, 2)\n",
        "\n",
        "actual = estimate_probability(\"cat\", [\"a\"], unigram_dictionary, bigram_dictionary, len(vocabulary))\n",
        "\n",
        "expected = 0.3333\n",
        "\n",
        "print(f\"The estimated probability of word 'cat' given the previous n-gram 'a' is: {actual:.4f}\")\n",
        "expect(math.isclose(actual, expected, abs_tol=1e-4)).to(be_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate probabilities for all words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import FrozenSet\n",
        "\n",
        "def estimate_probabilities(previous_n_gram: List[str], \n",
        "                            n_gram_counts: DefaultDict[Tuple[str], int],\n",
        "                            n_plus1_gram_counts: DefaultDict[Tuple[str],int],\n",
        "                            vocabulary: FrozenSet[str],\n",
        "                            k:float=1.0):\n",
        "    \"\"\"\n",
        "    Estimate the probabilities of next word using the n-gram counts with k-smoothing\n",
        "        Args:\n",
        "            previous_n_gram Tuple[str]: Sequence of words of length\n",
        "            n_gram_counts DefaultDict[Tuple[str], int]: Dictionary of counts of n-grams\n",
        "            n_plus1_gram_counts DefaultDict[Tuple[str], int]: Dictionary of counts of (n+1)-grams\n",
        "            vocabulary List[str]: List of words\n",
        "            k float: Smoothing parameter. Positive constant\n",
        "        Returns:\n",
        "            probabilities Dict[str, int]: A dictionary mapping from next words to the probability\n",
        "    \"\"\"\n",
        "\n",
        "    # Add end_token and unknown_token to the vocabulary\n",
        "    # start_token is not needed since it should not appear as next word\n",
        "    vocabulary_list = list(vocabulary)+ [\"<e>\", \"<unk>\"]\n",
        "    vocabulary_size = len(vocabulary_list)\n",
        "\n",
        "    probabilities = dict()\n",
        "    for word in vocabulary_list:\n",
        "        probability = estimate_probability(word,  previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k)\n",
        "        probabilities[word] = probability\n",
        "    \n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence = ['<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'this')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'cat')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'is')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'dog')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'a')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'i')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', 'like')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', '<e>')\n",
            "previous_n_gram = ('a',)\n",
            "n_plus1_gram = ('a', '<unk>')\n",
            "{'this': 0.09090909090909091, 'cat': 0.2727272727272727, 'is': 0.09090909090909091, 'dog': 0.09090909090909091, 'a': 0.09090909090909091, 'i': 0.09090909090909091, 'like': 0.09090909090909091, '<e>': 0.09090909090909091, '<unk>': 0.09090909090909091}\n"
          ]
        }
      ],
      "source": [
        "from expects import expect, have_keys\n",
        "\n",
        "sentences = [[\"i\",\"like\", \"a\", \"cat\"],\n",
        "             [\"this\", \"dog\", \"is\", \"like\", \"a\", \"cat\"]]\n",
        "\n",
        "vocabulary = frozenset(sentences[0]).union(frozenset(sentences[1]))\n",
        "unigram_counts = compute_ngram_dictionary(sentences, 1)\n",
        "bigram_counts = compute_ngram_dictionary(sentences, 2)\n",
        "\n",
        "actual = estimate_probabilities(\"a\", unigram_counts, bigram_counts, vocabulary, k=1)\n",
        "print(actual)\n",
        "expected = {'a': 0.09090909090909091,\n",
        "            'is': 0.09090909090909091,\n",
        "            'like': 0.09090909090909091,\n",
        "            'i': 0.09090909090909091,\n",
        "            'this': 0.09090909090909091,\n",
        "            'dog': 0.09090909090909091,\n",
        "            'cat': 0.2727272727272727,\n",
        "            '<e>': 0.09090909090909091,\n",
        "            '<unk>': 0.09090909090909091}\n",
        "expect(actual).to(have_keys(**expected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence = ['<s>', '<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'this')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'cat')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'is')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'dog')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'a')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'i')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', 'like')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', '<e>')\n",
            "previous_n_gram = ('<s>', '<s>')\n",
            "n_plus1_gram = ('<s>', '<s>', '<unk>')\n",
            "{'this': 0.18181818181818182, 'cat': 0.09090909090909091, 'is': 0.09090909090909091, 'dog': 0.09090909090909091, 'a': 0.09090909090909091, 'i': 0.18181818181818182, 'like': 0.09090909090909091, '<e>': 0.09090909090909091, '<unk>': 0.09090909090909091}\n"
          ]
        }
      ],
      "source": [
        "trigram_counts = compute_ngram_dictionary(sentences, 3)\n",
        "actual = estimate_probabilities([\"<s>\", \"<s>\"], bigram_counts, trigram_counts, vocabulary, k=1)\n",
        "print(actual)\n",
        "\n",
        "expected = {'a': 0.09090909090909091,\n",
        "            'is': 0.09090909090909091,\n",
        "            'like': 0.09090909090909091,\n",
        "            'i': 0.18181818181818182, \n",
        "            'this': 0.18181818181818182, \n",
        "            'dog': 0.09090909090909091, \n",
        "            'cat': 0.09090909090909091, \n",
        "            '<e>': 0.09090909090909091, \n",
        "            '<unk>': 0.09090909090909091}\n",
        "expect(actual).to(have_keys(**expected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Count and probability matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from typing import DefaultDict, Tuple, FrozenSet\n",
        "\n",
        "def make_count_matrix(n_plus1_gram_counts: DefaultDict[Tuple[str], int], vocabulary: FrozenSet[str]):\n",
        "    # Add <e> <unk> to the vocabulary\n",
        "    # <s> is omitted since it should not appear as the next word\n",
        "    vocabulary = vocabulary.union([\"<e>\", \"<unk>\"])\n",
        "    print(f\"vocabulary = {vocabulary}\")\n",
        "\n",
        "    # Obtain unique n-grams\n",
        "    n_grams = []\n",
        "    for n_plus1_gram in n_plus1_gram_counts.keys():\n",
        "        print(f\"key = {n_plus1_gram}\")\n",
        "        n_gram = n_plus1_gram[0:-1]\n",
        "        print(f\"n_gram = {n_gram}\")\n",
        "        n_grams.append(n_gram)\n",
        "    n_grams = list(set(n_grams))\n",
        "    print(f\"n_grams = {n_grams}\")\n",
        "\n",
        "    # mapping from n-gram to row\n",
        "    row_index = {n_gram: i for i, n_gram in enumerate(n_grams)}\n",
        "\n",
        "    # mapping from next word to column\n",
        "    col_index = {word: j for j, word in enumerate(vocabulary)}\n",
        "\n",
        "    n_rows = len(n_grams)\n",
        "    n_cols = len(vocabulary)\n",
        "    count_matrix = np.zeros((n_rows, n_cols))\n",
        "\n",
        "    for n_plus1_gram, count in n_plus1_gram_counts.items():\n",
        "        n_gram = n_plus1_gram[0:-1]\n",
        "        word = n_plus1_gram[-1]\n",
        "\n",
        "        if word not in vocabulary:\n",
        "            continue\n",
        "        i = row_index[n_gram]\n",
        "        j = col_index[word]\n",
        "        count_matrix[i, j] = count\n",
        "    \n",
        "    print(f\"count_matrix = {count_matrix}\")\n",
        "    count_matrix = pd.DataFrame(count_matrix, index=n_grams, columns=vocabulary)\n",
        "    return count_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence = ['<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "bigram_counts\n",
            "vocabulary = frozenset({'this', '<e>', 'is', 'cat', 'dog', 'a', 'i', 'like', '<unk>'})\n",
            "key = ('<s>', '<s>')\n",
            "n_gram = ('<s>',)\n",
            "key = ('<s>', 'i')\n",
            "n_gram = ('<s>',)\n",
            "key = ('i', 'like')\n",
            "n_gram = ('i',)\n",
            "key = ('like', 'a')\n",
            "n_gram = ('like',)\n",
            "key = ('a', 'cat')\n",
            "n_gram = ('a',)\n",
            "key = ('cat', '<e>')\n",
            "n_gram = ('cat',)\n",
            "key = ('<s>', 'this')\n",
            "n_gram = ('<s>',)\n",
            "key = ('this', 'dog')\n",
            "n_gram = ('this',)\n",
            "key = ('dog', 'is')\n",
            "n_gram = ('dog',)\n",
            "key = ('is', 'like')\n",
            "n_gram = ('is',)\n",
            "n_grams = [('<s>',), ('cat',), ('like',), ('this',), ('a',), ('dog',), ('i',), ('is',)]\n",
            "count_matrix = [[1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "|           |   this |   <e> |   is |   cat |   dog |   a |   i |   like |   <unk> |\n",
            "|-----------+--------+-------+------+-------+-------+-----+-----+--------+---------|\n",
            "| ('<s>',)  |      1 |     0 |    0 |     0 |     0 |   0 |   1 |      0 |       0 |\n",
            "| ('cat',)  |      0 |     2 |    0 |     0 |     0 |   0 |   0 |      0 |       0 |\n",
            "| ('like',) |      0 |     0 |    0 |     0 |     0 |   2 |   0 |      0 |       0 |\n",
            "| ('this',) |      0 |     0 |    0 |     0 |     1 |   0 |   0 |      0 |       0 |\n",
            "| ('a',)    |      0 |     0 |    0 |     2 |     0 |   0 |   0 |      0 |       0 |\n",
            "| ('dog',)  |      0 |     0 |    1 |     0 |     0 |   0 |   0 |      0 |       0 |\n",
            "| ('i',)    |      0 |     0 |    0 |     0 |     0 |   0 |   0 |      1 |       0 |\n",
            "| ('is',)   |      0 |     0 |    0 |     0 |     0 |   0 |   0 |      1 |       0 |\n"
          ]
        }
      ],
      "source": [
        "sentences = [[\"i\", \"like\", \"a\", \"cat\"],\n",
        "             [\"this\", \"dog\", \"is\", \"like\", \"a\", \"cat\"]]\n",
        "vocabulary = frozenset(sentences[0]).union(frozenset(sentences[1]))\n",
        "bigram_counts = compute_ngram_dictionary(sentences, 2)\n",
        "\n",
        "print(\"bigram_counts\")\n",
        "print(TABLE(make_count_matrix(bigram_counts, vocabulary)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trigram counts\n",
            "sentence = ['<s>', '<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "vocabulary = frozenset({'this', '<e>', 'is', 'cat', 'dog', 'a', 'i', 'like', '<unk>'})\n",
            "key = ('<s>', '<s>', '<s>')\n",
            "n_gram = ('<s>', '<s>')\n",
            "key = ('<s>', '<s>', 'i')\n",
            "n_gram = ('<s>', '<s>')\n",
            "key = ('<s>', 'i', 'like')\n",
            "n_gram = ('<s>', 'i')\n",
            "key = ('i', 'like', 'a')\n",
            "n_gram = ('i', 'like')\n",
            "key = ('like', 'a', 'cat')\n",
            "n_gram = ('like', 'a')\n",
            "key = ('a', 'cat', '<e>')\n",
            "n_gram = ('a', 'cat')\n",
            "key = ('<s>', '<s>', 'this')\n",
            "n_gram = ('<s>', '<s>')\n",
            "key = ('<s>', 'this', 'dog')\n",
            "n_gram = ('<s>', 'this')\n",
            "key = ('this', 'dog', 'is')\n",
            "n_gram = ('this', 'dog')\n",
            "key = ('dog', 'is', 'like')\n",
            "n_gram = ('dog', 'is')\n",
            "key = ('is', 'like', 'a')\n",
            "n_gram = ('is', 'like')\n",
            "n_grams = [('a', 'cat'), ('this', 'dog'), ('dog', 'is'), ('<s>', 'i'), ('<s>', 'this'), ('i', 'like'), ('like', 'a'), ('<s>', '<s>'), ('is', 'like')]\n",
            "count_matrix = [[0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "|                 |   this |   <e> |   is |   cat |   dog |   a |   i |   like |   <unk> |\n",
            "|-----------------+--------+-------+------+-------+-------+-----+-----+--------+---------|\n",
            "| ('a', 'cat')    |      0 |     2 |    0 |     0 |     0 |   0 |   0 |      0 |       0 |\n",
            "| ('this', 'dog') |      0 |     0 |    1 |     0 |     0 |   0 |   0 |      0 |       0 |\n",
            "| ('dog', 'is')   |      0 |     0 |    0 |     0 |     0 |   0 |   0 |      1 |       0 |\n",
            "| ('<s>', 'i')    |      0 |     0 |    0 |     0 |     0 |   0 |   0 |      1 |       0 |\n",
            "| ('<s>', 'this') |      0 |     0 |    0 |     0 |     1 |   0 |   0 |      0 |       0 |\n",
            "| ('i', 'like')   |      0 |     0 |    0 |     0 |     0 |   1 |   0 |      0 |       0 |\n",
            "| ('like', 'a')   |      0 |     0 |    0 |     2 |     0 |   0 |   0 |      0 |       0 |\n",
            "| ('<s>', '<s>')  |      1 |     0 |    0 |     0 |     0 |   0 |   1 |      0 |       0 |\n",
            "| ('is', 'like')  |      0 |     0 |    0 |     0 |     0 |   1 |   0 |      0 |       0 |\n"
          ]
        }
      ],
      "source": [
        "print(\"trigram counts\")\n",
        "trigram_counts = compute_ngram_dictionary(sentences, 3)\n",
        "print(TABLE(make_count_matrix(trigram_counts, vocabulary)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probabilty Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_probability_matrix(n_plus1_gram_counts: DefaultDict[Tuple[str], int], vocabulary: FrozenSet[str], k:float=1.0):\n",
        "    count_matrix = make_count_matrix(n_plus1_gram_counts, vocabulary)\n",
        "    count_matrix += k\n",
        "    probability_matrix = count_matrix.div(count_matrix.sum(axis=\"columns\"), axis=\"rows\")\n",
        "    return probability_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence = ['<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'i', 'like', 'a', 'cat', '<e>')\n",
            "sentence = ['<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>']\n",
            "tuple sentence = ('<s>', '<s>', 'this', 'dog', 'is', 'like', 'a', 'cat', '<e>')\n",
            "bigram probabilties\n",
            "vocabulary = frozenset({'this', '<e>', 'is', 'cat', 'dog', 'a', 'i', 'like', '<unk>'})\n",
            "key = ('<s>', '<s>')\n",
            "n_gram = ('<s>',)\n",
            "key = ('<s>', 'i')\n",
            "n_gram = ('<s>',)\n",
            "key = ('i', 'like')\n",
            "n_gram = ('i',)\n",
            "key = ('like', 'a')\n",
            "n_gram = ('like',)\n",
            "key = ('a', 'cat')\n",
            "n_gram = ('a',)\n",
            "key = ('cat', '<e>')\n",
            "n_gram = ('cat',)\n",
            "key = ('<s>', 'this')\n",
            "n_gram = ('<s>',)\n",
            "key = ('this', 'dog')\n",
            "n_gram = ('this',)\n",
            "key = ('dog', 'is')\n",
            "n_gram = ('dog',)\n",
            "key = ('is', 'like')\n",
            "n_gram = ('is',)\n",
            "n_grams = [('<s>',), ('cat',), ('like',), ('this',), ('a',), ('dog',), ('i',), ('is',)]\n",
            "count_matrix = [[1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 2. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "|           |      this |       <e> |        is |       cat |       dog |         a |         i |      like |     <unk> |\n",
            "|-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------|\n",
            "| ('<s>',)  | 0.181818  | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.181818  | 0.0909091 | 0.0909091 |\n",
            "| ('cat',)  | 0.0909091 | 0.272727  | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 |\n",
            "| ('like',) | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.272727  | 0.0909091 | 0.0909091 | 0.0909091 |\n",
            "| ('this',) | 0.1       | 0.1       | 0.1       | 0.1       | 0.2       | 0.1       | 0.1       | 0.1       | 0.1       |\n",
            "| ('a',)    | 0.0909091 | 0.0909091 | 0.0909091 | 0.272727  | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 | 0.0909091 |\n",
            "| ('dog',)  | 0.1       | 0.1       | 0.2       | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       |\n",
            "| ('i',)    | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.2       | 0.1       |\n",
            "| ('is',)   | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.1       | 0.2       | 0.1       |\n"
          ]
        }
      ],
      "source": [
        "sentences = [[\"i\", \"like\", \"a\", \"cat\"],\n",
        "             [\"this\", \"dog\", \"is\", \"like\", \"a\", \"cat\"]]\n",
        "\n",
        "vocabulary = frozenset(sentences[0]).union(sentences[1])\n",
        "bigram_counts = compute_ngram_dictionary(sentences, 2)\n",
        "print(\"bigram probabilties\")\n",
        "print(TABLE(make_probability_matrix(bigram_counts, vocabulary, k=1)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04cd26984f914b7a8874049254fd0258": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c842c87e2044dcca0a14a63a0ff4670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "252d3ef4498f4028b50055c06f9cfb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bd1d041a9f04d36ae6fd00dbda17a01",
            "placeholder": "",
            "style": "IPY_MODEL_dabee55ea6d34f2da1e72d37ce8140ac",
            "value": "52002/52002[00:00&lt;00:00,74634.34examples/s]"
          }
        },
        "27d9078f648b410e8a8526aad4714dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef399f7b8654954ab4e6583eb6a7eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32dca3f9ee694f65b70100f0dc5427fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aeb773899024f04858793b194b075b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9b7a630e07e4a3893b4402d5d37ab72",
            "placeholder": "",
            "style": "IPY_MODEL_f175789a77204e528b9ffcf4974f7fe9",
            "value": "Downloadingreadme:100%"
          }
        },
        "574339849abc480b85aa734f758a56fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6262e507f1bf499b81eb0cbca23cd22d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd1d041a9f04d36ae6fd00dbda17a01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f09d0464bf84a21b921467e068afa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7240bda92d5843df997bcaee596da264": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7964bb38775e400cb5bc880ca2572eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5c4e06bdc29463bbe999660f40a801f",
            "max": 48393562,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a509a06d08e7497ca6629604c8e1a173",
            "value": 48393562
          }
        },
        "83f16dc964a948cea62d076f883e99c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b94920db784f4bfc9112ee94ebf41149",
            "placeholder": "",
            "style": "IPY_MODEL_6f09d0464bf84a21b921467e068afa6b",
            "value": "Generatingtrainsplit:100%"
          }
        },
        "84b7ff0eb2d34a7fa7091e66a09a7f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83f16dc964a948cea62d076f883e99c6",
              "IPY_MODEL_fb433e5b56cd42a5813861310f2693ce",
              "IPY_MODEL_252d3ef4498f4028b50055c06f9cfb7f"
            ],
            "layout": "IPY_MODEL_b7d3810df42046eabbf6b024d49060b9"
          }
        },
        "8a564412f2c345d68b703f5986e0ed83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bcc75607e0e4948a2d2f16e2c04548a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "947c503af7fb40e98d71cbea5041a8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7240bda92d5843df997bcaee596da264",
            "placeholder": "",
            "style": "IPY_MODEL_27d9078f648b410e8a8526aad4714dbd",
            "value": "3.38k/3.38k[00:00&lt;00:00,213kB/s]"
          }
        },
        "a509a06d08e7497ca6629604c8e1a173": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acea3c84d96c423d86494e7b3c0be4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6262e507f1bf499b81eb0cbca23cd22d",
            "placeholder": "",
            "style": "IPY_MODEL_1c842c87e2044dcca0a14a63a0ff4670",
            "value": "Downloadingdata:100%"
          }
        },
        "b7d3810df42046eabbf6b024d49060b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94920db784f4bfc9112ee94ebf41149": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6959e78946d4dc2bcb241820f4a6ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b7a630e07e4a3893b4402d5d37ab72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb038298cc54251ab9cb7cc802c3c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aeb773899024f04858793b194b075b5",
              "IPY_MODEL_cfa76cf30fad4426b711533905a6bdde",
              "IPY_MODEL_947c503af7fb40e98d71cbea5041a8b8"
            ],
            "layout": "IPY_MODEL_04cd26984f914b7a8874049254fd0258"
          }
        },
        "cfa76cf30fad4426b711533905a6bdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32dca3f9ee694f65b70100f0dc5427fc",
            "max": 3385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bcc75607e0e4948a2d2f16e2c04548a",
            "value": 3385
          }
        },
        "d5c4e06bdc29463bbe999660f40a801f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7cf1524a9bd4dad8ee8bf7fc9d773bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabee55ea6d34f2da1e72d37ce8140ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e976d14a24a1473e9d7dc40e9ca0a6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6959e78946d4dc2bcb241820f4a6ce2",
            "placeholder": "",
            "style": "IPY_MODEL_8a564412f2c345d68b703f5986e0ed83",
            "value": "48.4M/48.4M[00:00&lt;00:00,77.7MB/s]"
          }
        },
        "f0092bfa570649b29f7d868eb6ce21b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acea3c84d96c423d86494e7b3c0be4b7",
              "IPY_MODEL_7964bb38775e400cb5bc880ca2572eae",
              "IPY_MODEL_e976d14a24a1473e9d7dc40e9ca0a6ef"
            ],
            "layout": "IPY_MODEL_2ef399f7b8654954ab4e6583eb6a7eea"
          }
        },
        "f175789a77204e528b9ffcf4974f7fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb433e5b56cd42a5813861310f2693ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7cf1524a9bd4dad8ee8bf7fc9d773bf",
            "max": 52002,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_574339849abc480b85aa734f758a56fe",
            "value": 52002
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
